---
title: "Stats 101"
output: 
  flexdashboard::flex_dashboard:
    orientation: columns
    vertical_layout: scroll
    css: flexdashboard.css
runtime: shiny
---

```{r setup, include=FALSE}
library(dplyr)
library(tidyr)
library(shiny)
library(DT)
library(flexdashboard)
library(ggplot2)
library(googlesheets)
library(skimr)
library(modelr)
library(ggbeeswarm)
library(forcats)
library(stringr)
gs_auth("googlesheets_token.rds")

getdata <- function() {
  sheet<-gs_title("About you (Responses)")
  df<-gs_read(sheet) 
  names(df)<-c("id","focus", "age", "happy","income")
 df<- df %>%
     mutate(happy=happy=="Yes",
            age=coalesce(as.numeric(age),45),
            focus=fct_lump(focus, n=3)) %>%
   mutate(age=ifelse(age<10|age>70,70,age))
  return(df)
}

summarise_tbl<-function(df, col, sum){
    quo_col <- enquo(col)
    df %>% 
    group_by(!! quo_col) %>% 
    summarise(n=n(),median =median(age),mean = mean(age), sd=sd(age), min=min(age), max=max(age)) %>% 
    mutate_if(is.numeric,round, 2)
}
```


```{r}
results <- reactive({
  invalidateLater(30000, session)
  getdata()
  }
)

```

Intro
===================================== 

Agenda
-----------------------------------------------------------------------
**Welcome!**

Please fill out [bit.ly/stats101survey](http://bit.ly/stats101survey)

Agenda

- Gathering data
- Exploring it
- Comparing groups
- Predicting values

About me
-----------------------------------------------------------------------

About Me

- Data science consultant
- Microsoft AI MVP
- Lots of community stuff
- itsalocke.com
    + itsalocke.com/talks
- @theStephLocke @lockedata

Img {data-width=400}
-----------------------------------------------------------------------

<img src="https://itsalocke.com/img/ChibiSteph.svg" width="600px"></img>


Data
=====================================  
All data
-----------------------------------------------------------------------
### Records
```{r}
renderValueBox({
  p<-nrow(results())
  valueBox(p,caption = "Records", icon="fa-hashtag",color = "primary")
})
```

### Table

```{r}
renderDataTable({results()})
```

Tables
=====================================  

- **Mean** is the sum of all values divided by the number of values
- **Standard deviation** is how far away you have to go from the mean to get most values

### Normal

```{r}
 ggplot(data = data.frame(x = c(-3, 3)), aes(x)) +
  stat_function(fun = dnorm, n = 101, args = list(mean = 0, sd = 1)) + ylab("") +
  scale_y_continuous(breaks = NULL)+ 
    theme_minimal(base_size=18)
```

### Happy 

```{r}
renderDataTable({
  summarise_tbl(results() , happy)
}, options = list(
  bPaginate = FALSE
))
```

### Salary

```{r}
renderDataTable({
  summarise_tbl(results() , income)
}, options = list(
  bPaginate = FALSE
))
```

### Focus

```{r}
renderDataTable({
  summarise_tbl(results() , focus)
}, options = list(
  bPaginate = FALSE
))
```

Charts
=====================================  

Age
-----------------------------------------------------------------------
### Happy with job 1
```{r}
renderPlot({
  ggplot(results(), aes(x = age, colour= happy, group=happy)) +
    geom_density() + 
    theme_minimal(base_size=18) +
    labs(x = "Happy", y = "Age",
         title = "Age distribution  by happiness") 
})
```

### Happy with job 2
```{r}
renderPlot({
  ggplot(results(), aes(x = happy, y= age)) +
    geom_boxplot(alpha=0, colour="grey")+
    geom_beeswarm(colour = "#2165B6", size =3) + 
    theme_minimal(base_size=18) +
    labs(x = "Happy", y = "Age",
         title = "Age distribution  by happiness") 
})
```


### Focus 1
```{r}
renderPlot({
  ggplot(results(), aes(x = age, colour= focus, group=focus)) +
    geom_density() + 
    theme_minimal(base_size=18) +
    labs(x = "Happy", y = "Age",
         title = "Age distribution  by focus") 
})
```

### Focus 2
```{r}
renderPlot({
  ggplot(results(), aes(x = focus, y= age)) +
    geom_boxplot(alpha=0, colour="grey")+
    geom_beeswarm(colour = "#2165B6", size =3) + 
    theme_minimal(base_size=18) +
    labs(x = "Focus", y = "Age",
         title = "Age distribution by focus") 
})
```

### Income 1
```{r}
renderPlot({
  ggplot(results(), aes(x = age, colour= income, group=income)) +
    geom_density() + 
    theme_minimal(base_size=18) +
    labs(x = "Happy", y = "Age",
         title = "Age distribution by income") 
})
```

### Income 2
```{r}
renderPlot({
  ggplot(results(), aes(x = income, y= age)) +
    geom_boxplot(alpha=0, colour="grey")+
    geom_beeswarm(colour = "#2165B6", size =3) + 
    theme_minimal(base_size=18) +
    labs(x = "Focus", y = "Age",
         title = "Age distribution by income") 
})
```

Are happy people older?
=====================================  

Job satisfaction
-----------------------------------------------------------------------
Hypothesis: People who are unhappy with their job are older than those who are happy with their job.

A t-test takes two groups and determines how likely it is for the two values to be generated from the same data i.e. the two groups are not actually different. The smaller the result, the less likely the two groups are actually one group. You should set a threshold before hand - commonly 0.05!

Run a t-test in R using the `t.test()` function.


### Age of happy people
```{r}
renderValueBox({
  results() %>% 
    filter( happy) %>% 
    summarise(mean=mean(age)) ->
    yes.mean
  p<-round(yes.mean$mean,1)
  valueBox(p,caption = "Mean age of happy people", icon="fa-user",color = "primary")
})
```

### Age of unhappy people
```{r}
renderValueBox({
  results() %>% 
    filter( !happy) %>% 
    summarise(mean=mean(age)) ->
    no.mean
  p<-round(no.mean$mean,1)
  valueBox(p,caption = "Mean age of unhappy people", icon="fa-user",color = "warning")
})
```

### Are the mean's *really* different?
```{r}
renderValueBox({
  p<-round(t.test(age ~ happy, results())$p.value , 3)
  valueBox(p,caption = "Happiness T-Test", icon="fa-asterisk",color = ifelse(p<=0.05,"primary","danger"))
})
```

Can we predict age?
=====================================  

### Setup
Challenge: Based on the information provided, can we predict a person's age?

What sort of things do we need to consider first?

- Do we have sufficient volumes of data?
- Is there extra information we can use?
- Is there bias that will be reflected in our results?
- Are there data quality issues or changes to data capture that could impact results?

Then what?

- What types of models could fit our challenge?
- How will we evaluate whether we've got a good model?
- How are we going to test our predictions?

### Sampling

We typically take some **training** data for building out model and some **testing** data for checking whether it works.

```{r}
sliderInput("sampleper", "Training percent",min = 0, max=100,value = 70, step =1)
              
```

```{r}
set.seed(888)
sampled<-reactive({
  tr<-input$sampleper/100
  te<-1-tr
  resample_partition(results(),
                    c(train = tr,test = te ))
})
```

### Training size
```{r}
renderValueBox({
  p<-nrow(sampled()$train)
  valueBox(p,caption = "Training", icon="fa-hashtag")
})
```

### Testing size
```{r}
renderValueBox({
  p<-nrow(sampled()$test)
  valueBox(p,caption = "Testing", icon="fa-hashtag")
})
```

### Candidate models
We have a continuous variable that we're trying to predict. We have a lot of categorical variable inputs.

The simplest model would be using the average -- whether **mean** or **median**.

We can do a line of best fit model (known as linear regression).

[setosa.io](http://setosa.io/ev/ordinary-least-squares-regression/)

Another option is a decision tree since we have lots of categorical inputs.

[r2d3.us](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/)

### Using simple measures
```{r}
training<-reactive({as_data_frame(sampled()$train)})
testing<-reactive({as_data_frame(sampled()$test)})
```

The median age is `r reactive({median(training()$age)})`.

The mean age is `r reactive({round(mean(training()$age),1)})`.

```{r}
renderPlot({
qplot(data=training(), x=age) + geom_vline(aes(xintercept = median(training()$age)), colour="blue")+ geom_vline(aes(xintercept = mean(training()$age)),colour="red")+
    theme_minimal(base_size=18)
})
```

```{r}
renderPlot({
qplot(data=training(), x=age) + geom_vline(aes(xintercept = median(training()$age)), colour="blue")+ geom_vline(aes(xintercept = mean(training()$age)),colour="red")+
    theme_minimal(base_size=18)
})
```

### Using a line of best fit
If we used one variable to predict age, what would our predictions look like?

### Happy
`lm(age~happy, data=training)`
```{r}
happymodel<-reactive({lm(age~happy, data=training())})

```

```{r}

renderPlot({
  happymodel<-lm(age~happy, data=training())
training() %>% 
  group_by(happy) %>%
  summarise(n=n()) %>% 
  add_predictions(happymodel, "age") ->
  preds
ggplot(training(), aes(x=happy, y=age))+
  geom_point()+
  geom_point(data=preds, colour="blue", size=5)+
   theme_minimal(base_size=18)+
    labs(x = "Happy", y = "Age",
         title = "Age distribution  by happiness") 
})
```

### Focus
`lm(age~focus, data=training)`

```{r}

renderPlot({
  focusmodel<-lm(age~focus, data=training())
training() %>% 
  group_by(focus) %>%
  summarise(n=n()) %>% 
  add_predictions(focusmodel, "age") ->
  preds
ggplot(training(), aes(x=focus, y=age))+
  geom_point()+
  geom_point(data=preds, colour="blue", size=5)+
   theme_minimal(base_size=18)+
    labs(x = "Focus", y = "Age",
         title = "Age distribution  by focus") 
})
```

### Income
`lm(age~income, data=training)`

```{r}

renderPlot({
  incomemodel<-lm(age~income, data=training())
training() %>% 
  group_by(income) %>%
  summarise(n=n()) %>% 
  add_predictions(incomemodel, "age") ->
  preds
ggplot(training(), aes(x=income, y=age))+
  geom_point()+
  geom_point(data=preds, colour="blue", size=5)+
   theme_minimal(base_size=18)+
    labs(x = "Income", y = "Age",
         title = "Age distribution  by focus") 
})
```

### All the things
Combining multiple variables

`lm(age~focus + happy + income, data=training)`

```{r}

renderPlot({
  fullmodel<-lm(age~focus + happy + income, data=training())
training() %>% 
  group_by(focus, happy, income) %>%
  summarise(n=n()) %>% 
  add_predictions(fullmodel, "age") ->
  preds
ggplot(training(), aes(x=age, y=age))+
  geom_point()+
  geom_point(data=preds, colour="blue", size=5)+
   theme_minimal(base_size=18)+
    labs(x = "Age", y = "Age",
         title = "Age distribution") 
})
```

### Picking a model
You can pick models by different metrics based on your business success criteria. Here we're going to use the Root Mean Squared Error (RMSE) after making predictions on our test data. Whichever one has the smallest value, that is our most accurate model and we'll use that going forward.

Root Mean Squared Error is:

1. The difference between the predicted value and the actual value
2. Square this value to make every number positive (so they don't cancel out!) and to make big errors matter more
3. Take the average of these values
4. Use the root of the average to bring the value back down to absolute errors that are on the same scale as the predictions

The model that has the lowest RMSE typically has a lower about error than the other models.

### Results
```{r}
renderDataTable({
  
  happymodel<-lm(age~happy, data=training())
  focusmodel<-lm(age~focus, data=training())
  incomemodel<-lm(age~income, data=training())
  fullmodel<-lm(age~happy+focus+income, data=training())

 testing() %>%
  add_predictions(happymodel, "happymodel")%>%
  add_predictions(focusmodel, "focusmodel")%>%
  add_predictions(incomemodel, "incomemodel")%>%
  add_predictions(fullmodel, "fullmodel")%>%
  mutate(medianmodel=median(training()$age),
         meanmodel=round(mean(training()$age),1)) %>%
  gather(model, pred_age, ends_with("model")) %>%
  mutate(square_error=(pred_age-age)^2) %>%
  group_by(model) %>%
  summarise(RMSE=round(mean(square_error)^0.5,1))
  
}, options = list(
  bPaginate = FALSE
))
```

# Can we predict happiness?

### Decision trees
Decision trees build a flowchart for arriving at an outcome. It determines this flowchart iteratively, based on what improves the split(s) between outcomes the most from all the remaining columns.

`FFTrees()`

### Result
```{r}
library(FFTrees) 
renderPlot({
training() %>% 
  FFTrees(happy~age+income+focus, 
          data=.,
          data.test = testing()) %>% 
  plot(data="test")
})
```
